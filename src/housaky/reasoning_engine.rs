#![allow(clippy::format_push_string, clippy::self_only_used_in_recursion)]

use anyhow::Result;
use chrono::{DateTime, Utc};
use rand;
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use std::sync::Arc;
use tokio::sync::RwLock;
use tracing::{info, warn};

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
pub enum ReasoningType {
    ChainOfThought,
    ReAct,
    TreeOfThought,
    Reflexion,
    SelfConsistency,
    MultiStep,
    Comparative,
    Diagnostic,
    Creative,
    Strategic,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ReasoningStep {
    pub id: String,
    pub step_number: usize,
    pub thought: String,
    pub action: Option<String>,
    pub observation: Option<String>,
    pub confidence: f64,
    pub timestamp: DateTime<Utc>,
    pub dependencies: Vec<String>,
    pub metadata: HashMap<String, String>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ReasoningChain {
    pub id: String,
    pub query: String,
    pub reasoning_type: ReasoningType,
    pub steps: Vec<ReasoningStep>,
    pub conclusion: Option<String>,
    pub final_confidence: f64,
    pub created_at: DateTime<Utc>,
    pub completed_at: Option<DateTime<Utc>>,
    pub total_tokens: usize,
    pub branches: Vec<ReasoningBranch>,
    pub self_corrections: Vec<SelfCorrection>,
    pub insights: Vec<String>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ReasoningBranch {
    pub id: String,
    pub from_step: usize,
    pub alternative_path: Vec<ReasoningStep>,
    pub conclusion: Option<String>,
    pub score: f64,
    pub explored: bool,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SelfCorrection {
    pub step_number: usize,
    pub original_thought: String,
    pub correction: String,
    pub reason: String,
    pub timestamp: DateTime<Utc>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct IntrospectionResult {
    pub query: String,
    pub reasoning_trace: String,
    pub decision_points: Vec<DecisionPoint>,
    pub alternative_paths: Vec<String>,
    pub uncertainty_sources: Vec<UncertaintySource>,
    pub knowledge_gaps: Vec<String>,
    pub recommendations: Vec<String>,
    pub confidence_breakdown: HashMap<String, f64>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DecisionPoint {
    pub step_number: usize,
    pub decision: String,
    pub alternatives: Vec<String>,
    pub selected_alternative: String,
    pub reason: String,
    pub confidence: f64,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct UncertaintySource {
    pub source: String,
    pub impact: f64,
    pub mitigation: Option<String>,
}

pub struct ReasoningEngine {
    chains: Arc<RwLock<HashMap<String, ReasoningChain>>>,
    active_chain: Arc<RwLock<Option<String>>>,
    max_steps: Arc<RwLock<usize>>,
    enable_branching: bool,
    enable_self_correction: bool,
    confidence_threshold: f64,
}

impl ReasoningEngine {
    pub fn new() -> Self {
        Self {
            chains: Arc::new(RwLock::new(HashMap::new())),
            active_chain: Arc::new(RwLock::new(None)),
            max_steps: Arc::new(RwLock::new(20)),
            enable_branching: true,
            enable_self_correction: true,
            confidence_threshold: 0.7,
        }
    }

    pub async fn set_max_steps(&self, max_steps: usize) -> Result<()> {
        if !(5..=60).contains(&max_steps) {
            return Err(anyhow::anyhow!(
                "max_steps out of range: {} (expected 5..=60)",
                max_steps
            ));
        }

        *self.max_steps.write().await = max_steps;
        Ok(())
    }

    pub async fn get_max_steps(&self) -> usize {
        *self.max_steps.read().await
    }

    pub async fn start_reasoning(
        &self,
        query: &str,
        reasoning_type: ReasoningType,
    ) -> Result<String> {
        let reasoning_type_str = format!("{:?}", reasoning_type);
        let chain = ReasoningChain {
            id: format!("chain_{}", uuid::Uuid::new_v4()),
            query: query.to_string(),
            reasoning_type,
            steps: Vec::new(),
            conclusion: None,
            final_confidence: 0.0,
            created_at: Utc::now(),
            completed_at: None,
            total_tokens: 0,
            branches: Vec::new(),
            self_corrections: Vec::new(),
            insights: Vec::new(),
        };

        let id = chain.id.clone();
        self.chains.write().await.insert(id.clone(), chain);
        *self.active_chain.write().await = Some(id.clone());

        info!(
            "Started {} reasoning chain for: {}",
            reasoning_type_str,
            query.chars().take(50).collect::<String>()
        );

        Ok(id)
    }

    pub async fn add_step(
        &self,
        chain_id: &str,
        thought: &str,
        action: Option<&str>,
    ) -> Result<usize> {
        let max_steps = *self.max_steps.read().await;
        let mut chains = self.chains.write().await;

        if let Some(chain) = chains.get_mut(chain_id) {
            let step_number = chain.steps.len() + 1;

            if step_number > max_steps {
                warn!("Max reasoning steps reached for chain {}", chain_id);
                return Err(anyhow::anyhow!("Max reasoning steps exceeded"));
            }

            let step = ReasoningStep {
                id: format!("step_{}_{}", chain_id, step_number),
                step_number,
                thought: thought.to_string(),
                action: action.map(|s| s.to_string()),
                observation: None,
                confidence: 0.8,
                timestamp: Utc::now(),
                dependencies: if step_number > 1 {
                    vec![format!("step_{}_{}", chain_id, step_number - 1)]
                } else {
                    Vec::new()
                },
                metadata: HashMap::new(),
            };

            chain.steps.push(step);
            chain.total_tokens += thought.len() / 4;

            info!("Added reasoning step {} to chain {}", step_number, chain_id);

            return Ok(step_number);
        }

        Err(anyhow::anyhow!("Chain not found: {}", chain_id))
    }

    pub async fn add_observation(
        &self,
        chain_id: &str,
        step_number: usize,
        observation: &str,
    ) -> Result<()> {
        let mut chains = self.chains.write().await;

        if let Some(chain) = chains.get_mut(chain_id) {
            if let Some(step) = chain
                .steps
                .iter_mut()
                .find(|s| s.step_number == step_number)
            {
                step.observation = Some(observation.to_string());
                step.confidence = self.calculate_step_confidence(&step.thought, observation);

                info!(
                    "Added observation to step {} in chain {}",
                    step_number, chain_id
                );
            }
        }

        Ok(())
    }

    fn calculate_step_confidence(&self, thought: &str, observation: &str) -> f64 {
        let thought_lower = thought.to_lowercase();
        let obs_lower = observation.to_lowercase();

        let thought_words: std::collections::HashSet<_> =
            thought_lower.split_whitespace().collect();
        let obs_words: std::collections::HashSet<_> = obs_lower.split_whitespace().collect();

        let overlap = thought_words.intersection(&obs_words).count();
        let total = thought_words.union(&obs_words).count();

        if total == 0 {
            return 0.5;
        }

        let relevance = overlap as f64 / total as f64;
        let base_confidence = 0.7;

        base_confidence + (relevance * 0.3)
    }

    pub async fn conclude(&self, chain_id: &str, conclusion: &str) -> Result<()> {
        let mut chains = self.chains.write().await;

        if let Some(chain) = chains.get_mut(chain_id) {
            chain.conclusion = Some(conclusion.to_string());
            chain.final_confidence = self.calculate_final_confidence(chain);
            chain.completed_at = Some(Utc::now());

            *self.active_chain.write().await = None;

            info!(
                "Concluded reasoning chain {} with confidence {:.2}",
                chain_id, chain.final_confidence
            );
        }

        Ok(())
    }

    fn calculate_final_confidence(&self, chain: &ReasoningChain) -> f64 {
        if chain.steps.is_empty() {
            return 0.0;
        }

        let avg_confidence: f64 =
            chain.steps.iter().map(|s| s.confidence).sum::<f64>() / chain.steps.len() as f64;

        let correction_penalty = chain.self_corrections.len() as f64 * 0.05;
        let branch_bonus = if chain.branches.iter().any(|b| b.explored) {
            0.05
        } else {
            0.0
        };

        (avg_confidence - correction_penalty + branch_bonus).clamp(0.0, 1.0)
    }

    pub async fn add_branch(
        &self,
        chain_id: &str,
        from_step: usize,
        alternative_thoughts: Vec<&str>,
    ) -> Result<String> {
        if !self.enable_branching {
            return Err(anyhow::anyhow!("Branching is disabled"));
        }

        let mut chains = self.chains.write().await;

        if let Some(chain) = chains.get_mut(chain_id) {
            let branch = ReasoningBranch {
                id: format!("branch_{}", uuid::Uuid::new_v4()),
                from_step,
                alternative_path: alternative_thoughts
                    .iter()
                    .enumerate()
                    .map(|(i, thought)| ReasoningStep {
                        id: format!("branch_step_{}_{}", chain_id, i),
                        step_number: i + 1,
                        thought: thought.to_string(),
                        action: None,
                        observation: None,
                        confidence: 0.7,
                        timestamp: Utc::now(),
                        dependencies: Vec::new(),
                        metadata: HashMap::new(),
                    })
                    .collect(),
                conclusion: None,
                score: 0.0,
                explored: false,
            };

            let branch_id = branch.id.clone();
            chain.branches.push(branch);

            info!(
                "Added reasoning branch from step {} in chain {}",
                from_step, chain_id
            );

            return Ok(branch_id);
        }

        Err(anyhow::anyhow!("Chain not found: {}", chain_id))
    }

    pub async fn self_correct(
        &self,
        chain_id: &str,
        step_number: usize,
        correction: &str,
        reason: &str,
    ) -> Result<()> {
        if !self.enable_self_correction {
            return Err(anyhow::anyhow!("Self-correction is disabled"));
        }

        let mut chains = self.chains.write().await;

        if let Some(chain) = chains.get_mut(chain_id) {
            if let Some(step) = chain.steps.get(step_number - 1) {
                let self_correction = SelfCorrection {
                    step_number,
                    original_thought: step.thought.clone(),
                    correction: correction.to_string(),
                    reason: reason.to_string(),
                    timestamp: Utc::now(),
                };

                chain.self_corrections.push(self_correction);

                info!(
                    "Added self-correction for step {} in chain {}: {}",
                    step_number, chain_id, reason
                );
            }
        }

        Ok(())
    }

    pub async fn introspect(&self, chain_id: &str) -> Result<IntrospectionResult> {
        let chains = self.chains.read().await;

        if let Some(chain) = chains.get(chain_id) {
            let reasoning_trace = self.format_reasoning_trace(chain);
            let decision_points = self.extract_decision_points(chain);
            let alternative_paths = self.extract_alternative_paths(chain);
            let uncertainty_sources = self.identify_uncertainty(chain);
            let knowledge_gaps = self.identify_knowledge_gaps(chain);
            let recommendations = self.generate_recommendations(chain);
            let confidence_breakdown = self.build_confidence_breakdown(chain);

            Ok(IntrospectionResult {
                query: chain.query.clone(),
                reasoning_trace,
                decision_points,
                alternative_paths,
                uncertainty_sources,
                knowledge_gaps,
                recommendations,
                confidence_breakdown,
            })
        } else {
            Err(anyhow::anyhow!("Chain not found: {}", chain_id))
        }
    }

    fn format_reasoning_trace(&self, chain: &ReasoningChain) -> String {
        let mut trace = String::new();

        trace.push_str(&format!("Query: {}\n\n", chain.query));
        trace.push_str(&format!("Reasoning Type: {:?}\n\n", chain.reasoning_type));

        for step in &chain.steps {
            trace.push_str(&format!("Step {}:\n", step.step_number));
            trace.push_str(&format!("  Thought: {}\n", step.thought));

            if let Some(ref action) = step.action {
                trace.push_str(&format!("  Action: {}\n", action));
            }

            if let Some(ref observation) = step.observation {
                trace.push_str(&format!("  Observation: {}\n", observation));
            }

            trace.push_str(&format!("  Confidence: {:.2}\n\n", step.confidence));
        }

        if let Some(ref conclusion) = chain.conclusion {
            trace.push_str(&format!("Conclusion: {}\n", conclusion));
            trace.push_str(&format!(
                "Final Confidence: {:.2}\n",
                chain.final_confidence
            ));
        }

        for correction in &chain.self_corrections {
            trace.push_str(&format!(
                "\nCorrection at step {}: {}\n",
                correction.step_number, correction.correction
            ));
            trace.push_str(&format!("  Reason: {}\n", correction.reason));
        }

        trace
    }

    fn extract_decision_points(&self, chain: &ReasoningChain) -> Vec<DecisionPoint> {
        chain
            .steps
            .iter()
            .filter(|s| s.action.is_some())
            .map(|step| DecisionPoint {
                step_number: step.step_number,
                decision: step.action.clone().unwrap_or_default(),
                alternatives: chain
                    .branches
                    .iter()
                    .filter(|b| b.from_step == step.step_number)
                    .map(|b| {
                        b.alternative_path
                            .first()
                            .map(|s| s.thought.clone())
                            .unwrap_or_default()
                    })
                    .collect(),
                selected_alternative: step.thought.clone(),
                reason: format!("Based on observation at step {}", step.step_number),
                confidence: step.confidence,
            })
            .collect()
    }

    fn extract_alternative_paths(&self, chain: &ReasoningChain) -> Vec<String> {
        chain
            .branches
            .iter()
            .filter(|b| b.explored)
            .map(|b| {
                b.alternative_path
                    .iter()
                    .map(|s| s.thought.clone())
                    .collect::<Vec<_>>()
                    .join(" â†’ ")
            })
            .collect()
    }

    fn identify_uncertainty(&self, chain: &ReasoningChain) -> Vec<UncertaintySource> {
        chain
            .steps
            .iter()
            .filter(|s| s.confidence < self.confidence_threshold)
            .map(|s| UncertaintySource {
                source: format!(
                    "Low confidence at step {}: {}",
                    s.step_number,
                    s.thought.chars().take(50).collect::<String>()
                ),
                impact: 1.0 - s.confidence,
                mitigation: Some(
                    "Consider gathering more information or exploring alternatives".to_string(),
                ),
            })
            .collect()
    }

    fn identify_knowledge_gaps(&self, chain: &ReasoningChain) -> Vec<String> {
        let mut gaps = Vec::new();

        for step in &chain.steps {
            if step.thought.contains("unknown")
                || step.thought.contains("unclear")
                || step.thought.contains("not sure")
                || step.confidence < 0.5
            {
                gaps.push(format!(
                    "Knowledge gap at step {}: {}",
                    step.step_number,
                    step.thought.chars().take(100).collect::<String>()
                ));
            }
        }

        if let Some(ref conclusion) = chain.conclusion {
            if chain.final_confidence < 0.7 {
                gaps.push(format!(
                    "Low confidence conclusion: {}",
                    conclusion.chars().take(100).collect::<String>()
                ));
            }
        }

        gaps
    }

    fn generate_recommendations(&self, chain: &ReasoningChain) -> Vec<String> {
        let mut recommendations = Vec::new();

        if chain.self_corrections.len() > 2 {
            recommendations.push("Consider using a more systematic reasoning approach".to_string());
        }

        if chain.steps.iter().any(|s| s.confidence < 0.6) {
            recommendations
                .push("Gather additional information before drawing conclusions".to_string());
        }

        if chain.branches.is_empty() && chain.steps.len() > 5 {
            recommendations.push("Consider exploring alternative reasoning paths".to_string());
        }

        if chain.final_confidence < 0.8 {
            recommendations.push("Verify conclusion with independent validation".to_string());
        }

        recommendations
    }

    fn build_confidence_breakdown(&self, chain: &ReasoningChain) -> HashMap<String, f64> {
        let mut breakdown = HashMap::new();

        breakdown.insert("overall".to_string(), chain.final_confidence);

        if !chain.steps.is_empty() {
            let avg_step_confidence: f64 =
                chain.steps.iter().map(|s| s.confidence).sum::<f64>() / chain.steps.len() as f64;
            breakdown.insert("step_average".to_string(), avg_step_confidence);
        }

        breakdown.insert(
            "correction_impact".to_string(),
            (chain.self_corrections.len() as f64 * 0.05).min(1.0),
        );

        breakdown.insert(
            "branch_coverage".to_string(),
            if chain.branches.iter().any(|b| b.explored) {
                0.9
            } else {
                0.5
            },
        );

        breakdown
    }

    pub async fn get_chain(&self, chain_id: &str) -> Option<ReasoningChain> {
        let chains = self.chains.read().await;
        chains.get(chain_id).cloned()
    }

    pub async fn explain_reasoning(&self, chain_id: &str) -> Result<String> {
        let introspection = self.introspect(chain_id).await?;

        let mut explanation = String::new();

        explanation.push_str("# Reasoning Explanation\n\n");
        explanation.push_str(&format!("**Query**: {}\n\n", introspection.query));
        explanation.push_str("## Reasoning Trace\n\n");
        explanation.push_str(&introspection.reasoning_trace);
        explanation.push_str("\n\n## Decision Points\n\n");

        for dp in &introspection.decision_points {
            explanation.push_str(&format!("- **Step {}**: {}\n", dp.step_number, dp.decision));
            explanation.push_str(&format!("  - Confidence: {:.2}\n", dp.confidence));
            if !dp.alternatives.is_empty() {
                explanation.push_str("  - Alternatives considered:\n");
                for alt in &dp.alternatives {
                    explanation.push_str(&format!("    - {}\n", alt));
                }
            }
        }

        if !introspection.uncertainty_sources.is_empty() {
            explanation.push_str("\n## Sources of Uncertainty\n\n");
            for us in &introspection.uncertainty_sources {
                explanation.push_str(&format!("- {} (impact: {:.2})\n", us.source, us.impact));
            }
        }

        if !introspection.recommendations.is_empty() {
            explanation.push_str("\n## Recommendations\n\n");
            for rec in &introspection.recommendations {
                explanation.push_str(&format!("- {}\n", rec));
            }
        }

        Ok(explanation)
    }

    pub fn generate_cot_prompt(&self, query: &str) -> String {
        format!(
            r#"Think through this step by step using chain-of-thought reasoning.

Query: {}

Format your response as:
**Thought 1**: [Your initial understanding and first step]
**Action 1**: [What you would do next]
**Observation 1**: [What you observe from the action]
...
**Conclusion**: [Your final answer with confidence]

Consider:
- Break down the problem into smaller steps
- Show your reasoning at each step
- Note any assumptions you make
- Identify uncertainty and knowledge gaps
- Consider alternative approaches
"#,
            query
        )
    }

    pub fn generate_react_prompt(&self, query: &str, available_tools: &[&str]) -> String {
        format!(
            r#"Use the ReAct (Reasoning + Acting) framework to solve this.

Query: {}

Available Tools: {}

For each step:
1. **Thought**: Think about what to do next
2. **Action**: Choose a tool and provide input
3. **Observation**: See what the tool returns

Continue until you have enough information to answer.

Format:
Thought 1: [Your reasoning]
Action 1: [tool_name: input]
Observation 1: [tool result]
...
Final Answer: [Your conclusion]
"#,
            query,
            available_tools.join(", ")
        )
    }

    pub fn generate_system_prompt(&self, reasoning_type: &ReasoningType) -> String {
        match reasoning_type {
            ReasoningType::ChainOfThought => {
                r#"You are a reasoning assistant that thinks step by step.
Break down complex problems into manageable steps.
Show your reasoning at each stage.
End with a clear, well-supported conclusion."#.to_string()
            }
            ReasoningType::ReAct => {
                r#"You are an advanced AI assistant with access to tools for reasoning and acting.

## ReAct Framework

Use this format for reasoning:
- **Thought**: Analyze what you know and what you need to find out
- **Action**: Use a tool to gather information
- **Observation**: Process the tool result
- Repeat until you have enough information
- **Final Answer**: Provide your conclusion

## Rules

1. Always start with a Thought
2. Each Action must use one of the available tools
3. Process Observations before the next Thought
4. Continue until you can provide a confident Final Answer
5. If uncertain, reflect on what you've learned

## Output Format

```
Thought 1: [your reasoning]
Action 1: [tool_name with parameters]
Observation 1: [tool result]
...
Final Answer: [your conclusion]
```
"#.to_string()
            }
            ReasoningType::TreeOfThought => {
                r#"You are an AI that explores multiple solution paths.

## Tree of Thoughts

1. Generate multiple different approaches to solve the problem
2. Evaluate each approach's feasibility and potential outcome
3. Compare approaches and select the best one
4. Explain why your chosen approach is superior

Consider at least 3 different paths and provide thorough analysis of each.
"#.to_string()
            }
            ReasoningType::Reflexion => {
                r#"You are a reflective AI that improves through self-evaluation.

## Reflexion Framework

1. **Initial Attempt**: Propose a solution
2. **Critique**: Identify potential issues
3. **Reflect**: Consider what went wrong and how to improve
4. **Refine**: Propose an improved solution

Always question your assumptions and look for weaknesses in your reasoning.
"#.to_string()
            }
            ReasoningType::SelfConsistency => {
                r#"You are an AI that values consistency in reasoning.

## Self-Consistency Framework

1. Generate multiple reasoning paths for the same question
2. Compare the conclusions
3. Identify the most consistent answer
4. Explain why this answer is most reliable

Consistency indicates robustness in your reasoning.
"#.to_string()
            }
            ReasoningType::MultiStep => {
                r#"You are an AI that breaks complex problems into steps.

## Multi-Step Framework

1. Identify the goal
2. List necessary steps
3. Execute each step in order
4. Verify progress after each step
5. Adjust plan if needed

Show clear progress markers between steps.
"#.to_string()
            }
            ReasoningType::Comparative => {
                r#"You are an AI skilled in comparative analysis.

## Comparative Framework

1. Identify the items to compare
2. List relevant criteria
3. Evaluate each item against criteria
4. Summarize differences and similarities
5. Provide a conclusion or recommendation

Be objective and balanced in your comparison.
"#.to_string()
            }
            ReasoningType::Diagnostic => {
                r#"You are an AI diagnostician.

## Diagnostic Framework

1. Observe symptoms or issues
2. List possible causes
3. Evaluate likelihood of each cause
4. Recommend tests or investigations
5. Identify the most probable root cause

Think like a doctor diagnosing an illness.
"#.to_string()
            }
            ReasoningType::Creative => {
                r#"You are a creative AI that thinks outside the box.

## Creative Framework

1. Understand the challenge
2. Brainstorm unconventional approaches
3. Combine ideas in novel ways
4. Evaluate feasibility
5. Present the most creative viable solution

Don't be afraid to suggest unusual solutions.
"#.to_string()
            }
            ReasoningType::Strategic => {
                r#"You are a strategic AI planner.

## Strategic Framework

1. Define objectives
2. Analyze current situation
3. Identify resources and constraints
4. Develop multiple strategies
5. Recommend the optimal path forward

Consider short-term and long-term implications.
"#.to_string()
            }
        }
    }

    pub fn generate_user_prompt(&self, query: &str, reasoning_type: &ReasoningType) -> String {
        match reasoning_type {
            ReasoningType::ChainOfThought => {
                format!(
                    "Think through this step by step:\n\n{}\n\n\
                     Show your reasoning at each step. End with a clear conclusion.",
                    query
                )
            }
            ReasoningType::TreeOfThought => {
                format!(
                    "Explore multiple approaches to solve:\n\n{}\n\n\
                     Consider at least 3 different paths and select the best one.",
                    query
                )
            }
            ReasoningType::MultiStep => {
                format!(
                    "Break down this problem into steps and solve it:\n\n{}\n\n\
                     Show clear progress after each step.",
                    query
                )
            }
            ReasoningType::Comparative => {
                format!(
                    "Compare and analyze the following:\n\n{}\n\n\
                     Provide a thorough comparison with a recommendation.",
                    query
                )
            }
            ReasoningType::Diagnostic => {
                format!(
                    "Diagnose or analyze this issue:\n\n{}\n\n\
                     Identify likely causes and recommend solutions.",
                    query
                )
            }
            ReasoningType::Creative => {
                format!(
                    "Solve this problem creatively:\n\n{}\n\n\
                     Explore unconventional approaches and novel solutions.",
                    query
                )
            }
            ReasoningType::Strategic => {
                format!(
                    "Develop a strategic plan for:\n\n{}\n\n\
                     Consider short-term and long-term implications.",
                    query
                )
            }
            ReasoningType::Reflexion => {
                format!(
                    "Solve this problem, then reflect on your solution:\n\n{}\n\n\
                     Identify any weaknesses and propose improvements.",
                    query
                )
            }
            ReasoningType::SelfConsistency => {
                format!(
                    "Solve this problem using multiple approaches:\n\n{}\n\n\
                     Compare your answers and identify the most consistent solution.",
                    query
                )
            }
            _ => query.to_string(),
        }
    }

    pub fn calculate_confidence(&self, steps: &[ReasoningStep], conclusion: &str) -> f64 {
        if steps.is_empty() {
            return 0.3;
        }

        let step_confidence: f64 =
            steps.iter().map(|s| s.confidence).sum::<f64>() / steps.len() as f64;

        let conclusion_bonus = if conclusion.len() > 20 { 0.1 } else { 0.0 };
        let step_bonus = if steps.len() >= 3 { 0.1 } else { 0.0 };

        (step_confidence + conclusion_bonus + step_bonus).min(1.0)
    }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct MCTSNode {
    pub state: String,
    pub action: Option<String>,
    pub visit_count: u64,
    pub total_value: f64,
    pub children: Vec<MCTSNode>,
    pub parent: Option<String>,
    pub depth: usize,
    pub expanded: bool,
}

impl MCTSNode {
    pub fn new(
        state: String,
        action: Option<String>,
        parent: Option<String>,
        depth: usize,
    ) -> Self {
        Self {
            state,
            action,
            visit_count: 0,
            total_value: 0.0,
            children: Vec::new(),
            parent,
            depth,
            expanded: false,
        }
    }

    pub fn value(&self) -> f64 {
        if self.visit_count == 0 {
            f64::MAX
        } else {
            self.total_value / self.visit_count as f64
        }
    }

    pub fn uct_value(&self, parent_visit_count: u64, exploration_constant: f64) -> f64 {
        if self.visit_count == 0 {
            f64::MAX
        } else {
            let exploitation = self.total_value / self.visit_count as f64;
            let exploration = exploration_constant
                * ((parent_visit_count as f64).ln() / self.visit_count as f64).sqrt();
            exploitation + exploration
        }
    }
}

pub struct MonteCarloTreeSearch {
    root: Option<MCTSNode>,
    max_depth: usize,
    max_iterations: usize,
    exploration_constant: f64,
    simulation_length: usize,
}

impl MonteCarloTreeSearch {
    pub fn new() -> Self {
        Self {
            root: None,
            max_depth: 10,
            max_iterations: 100,
            exploration_constant: 1.414,
            simulation_length: 5,
        }
    }

    pub fn with_config(max_depth: usize, max_iterations: usize, exploration_constant: f64) -> Self {
        Self {
            root: None,
            max_depth,
            max_iterations,
            exploration_constant,
            simulation_length: 5,
        }
    }

    pub fn initialize(&mut self, initial_state: String) {
        self.root = Some(MCTSNode::new(initial_state, None, None, 0));
    }

    pub fn search(
        &mut self,
        get_possible_actions: impl Fn(&str) -> Vec<String>,
        evaluate: impl Fn(&str) -> f64,
    ) -> Option<String> {
        let root_state = self.root.as_mut()?.state.clone();
        let mut current_state = root_state.clone();

        for _ in 0..self.max_iterations {
            let actions = get_possible_actions(&current_state);
            if actions.is_empty() {
                break;
            }

            let idx = rand::random::<usize>() % actions.len();
            let action = actions[idx].clone();
            current_state = format!("{} -> {}", current_state, action);

            let reward = evaluate(&current_state);

            if let Some(root) = self.root.as_mut() {
                root.visit_count += 1;
                root.total_value += reward;
            }
        }

        self.root.as_mut().and_then(|r| {
            r.children
                .iter()
                .max_by_key(|c| c.visit_count)
                .and_then(|c| c.action.clone())
        })
    }

    pub fn get_best_path(&self) -> Vec<String> {
        let mut path = Vec::new();

        if let Some(root) = &self.root {
            path.push(root.state.clone());

            let mut current = root.children.iter().max_by_key(|c| c.visit_count);

            while let Some(node) = current {
                path.push(node.state.clone());
                current = node.children.iter().max_by_key(|c| c.visit_count);
            }
        }

        path
    }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ReasoningStrategy {
    pub strategy_type: AdvancedReasoningType,
    pub confidence: f64,
    pub steps_taken: usize,
    pub alternatives_explored: Vec<String>,
    pub final_choice: Option<String>,
}

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
pub enum AdvancedReasoningType {
    MonteCarloTreeSearch,
    MonteCarlo,
    BeamSearch,
    AStar,
    GreedyBestFirst,
    Dijkstra,
    HillClimbing,
    SimulatedAnnealing,
    GeneticAlgorithm,
    DivideAndConquer,
    DynamicProgramming,
}

pub struct AdvancedReasoningEngine {
    mcts: MonteCarloTreeSearch,
    beam_width: usize,
    max_candidates: usize,
}

impl AdvancedReasoningEngine {
    pub fn new() -> Self {
        Self {
            mcts: MonteCarloTreeSearch::new(),
            beam_width: 5,
            max_candidates: 10,
        }
    }

    pub fn beam_search(
        &self,
        initial_state: &str,
        generate_neighbors: impl Fn(&str) -> Vec<(String, f64)>,
        evaluate: impl Fn(&str) -> f64,
        max_steps: usize,
    ) -> Vec<(String, f64)> {
        let mut beam = vec![(initial_state.to_string(), evaluate(initial_state))];

        for _ in 0..max_steps {
            let mut candidates = Vec::new();

            for (state, score) in &beam {
                let neighbors = generate_neighbors(state);
                for (neighbor, edge_cost) in neighbors {
                    let new_score = score + edge_cost;
                    candidates.push((neighbor, new_score));
                }
            }

            if candidates.is_empty() {
                break;
            }

            candidates.sort_by(|a, b| b.1.partial_cmp(&a.1).unwrap());
            beam = candidates.into_iter().take(self.beam_width).collect();
        }

        beam
    }

    pub fn greedy_best_first(
        &self,
        initial_state: &str,
        generate_neighbors: impl Fn(&str) -> Vec<String>,
        heuristic: impl Fn(&str) -> f64,
        goal_check: impl Fn(&str) -> bool,
        max_steps: usize,
    ) -> Option<String> {
        let mut frontier: Vec<(f64, String)> =
            vec![(heuristic(initial_state), initial_state.to_string())];
        let mut visited = std::collections::HashSet::new();

        for _ in 0..max_steps {
            if frontier.is_empty() {
                return None;
            }

            frontier.sort_by(|a, b| b.0.partial_cmp(&a.0).unwrap());
            let (_, current) = frontier.remove(0);

            if goal_check(&current) {
                return Some(current);
            }

            if visited.contains(&current) {
                continue;
            }
            visited.insert(current.clone());

            for neighbor in generate_neighbors(&current) {
                if !visited.contains(&neighbor) {
                    let priority = heuristic(&neighbor);
                    frontier.push((priority, neighbor));
                }
            }
        }

        None
    }

    pub fn simulated_annealing(
        &self,
        initial_state: &str,
        generate_neighbor: impl Fn(&str) -> String,
        evaluate: impl Fn(&str) -> f64,
        initial_temp: f64,
        cooling_rate: f64,
        min_temp: f64,
    ) -> (String, f64) {
        let mut current = initial_state.to_string();
        let mut current_energy = evaluate(&current);

        let mut best = current.clone();
        let mut best_energy = current_energy;

        let mut temp = initial_temp;

        while temp > min_temp {
            let next = generate_neighbor(&current);
            let next_energy = evaluate(&next);

            let delta = next_energy - current_energy;

            let should_accept = if delta > 0.0 {
                true
            } else {
                let probability = (delta / temp).exp();
                rand::random::<f64>() < probability
            };

            if should_accept {
                current = next;
                current_energy = next_energy;

                if current_energy > best_energy {
                    best = current.clone();
                    best_energy = current_energy;
                }
            }

            temp *= cooling_rate;
        }

        (best, best_energy)
    }

    pub fn divide_and_conquer(
        &self,
        problem: &str,
        split: impl Fn(&str) -> Vec<String>,
        solve_base: impl Fn(&str) -> Option<String>,
        merge: impl Fn(&[String]) -> String,
    ) -> Option<String> {
        let subproblems = split(problem);

        if subproblems.len() <= 2 {
            return solve_base(problem);
        }

        let mut solutions = Vec::new();
        for sub in subproblems {
            if let Some(solution) = self.divide_and_conquer(&sub, &split, &solve_base, &merge) {
                solutions.push(solution);
            }
        }

        if solutions.is_empty() {
            None
        } else {
            Some(merge(&solutions))
        }
    }
}

impl Default for MonteCarloTreeSearch {
    fn default() -> Self {
        Self::new()
    }
}

impl Default for AdvancedReasoningEngine {
    fn default() -> Self {
        Self::new()
    }
}
